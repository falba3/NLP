{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50d5307",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520011fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbbcad9cdb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchtext.vocab import GloVe\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea92e7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Load the Dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e05a270",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Load GloVe word embeddings\n",
    "glove = GloVe(name='6B', dim=50, cache=\"/tmp/glove/\")\n",
    "word_index = {word: idx + 1 for idx, word in enumerate(glove.itos)}\n",
    "embedding_matrix = glove.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966442ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Split the data\n",
    "X_train = dataset['train']['text']\n",
    "y_train = dataset['train']['label']\n",
    "\n",
    "X_test = dataset['test']['text']\n",
    "y_test = dataset['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a950f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Preparing Embedding Indices and tokenization\n",
    "embedding_index = {word: glove.vectors[glove.stoi[word]] for word in glove.stoi}\n",
    "\n",
    "def tokenize_and_index(sentences, embedding_index, max_length):\n",
    "    indexed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        indices = [glove.stoi.get(token, 0) for token in tokens]  # Uses index 0 for unknown tokens\n",
    "        indices = indices[:max_length]  # Truncate or pad to max_length\n",
    "        padded_indices = indices + [0] * (max_length - len(indices))  # To pad with zeros\n",
    "        indexed_sentences.append(padded_indices)\n",
    "    return indexed_sentences\n",
    "\n",
    "\n",
    "# Step 5: Tokenizing the sentences and then taking the index from static embeddings\n",
    "max_length = 100 \n",
    "X_train_indices = tokenize_and_index(X_train, embedding_index, max_length)\n",
    "X_test_indices = tokenize_and_index(X_test, embedding_index, max_length)\n",
    "\n",
    "# Converting data to tensors that the models can ingest\n",
    "X_train_tensor = torch.tensor(X_train_indices, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_indices, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26ea1922",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Defining functions to train and evaluate the model\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs, lr=0.001):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        predictions = torch.round(torch.sigmoid(outputs))\n",
    "        accuracy = (predictions.squeeze() == y_test).sum().item() / len(y_test)\n",
    "        f1 = f1_score(y_test.cpu().numpy(), predictions.squeeze().cpu().numpy())\n",
    "        print(f\"Accuracy: {accuracy}, F1 score: {f1}\")\n",
    "        return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b21791",
   "metadata": {},
   "source": [
    "# Final Model: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7c73c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StaticEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, kernel_sizes=[3, 4, 5], num_filters=100, dropout_prob=0.5):\n",
    "        super(StaticEmbeddingCNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_matrix.shape[1], out_channels=num_filters, kernel_size=ks)\n",
    "            for ks in kernel_sizes\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "\n",
    "        conv_outputs = [F.relu(conv(embedded)) for conv in self.convs] \n",
    "\n",
    "        pooled_outputs = [F.max_pool1d(conv_output, conv_output.size(2)).squeeze(2) for conv_output in conv_outputs]  # Pooling\n",
    "\n",
    "        concat = torch.cat(pooled_outputs, dim=1) \n",
    "\n",
    "        output = self.dropout(concat)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f991499",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7160917520523071\n",
      "Epoch 2/100, Loss: 0.7103981375694275\n",
      "Epoch 3/100, Loss: 0.7049252390861511\n",
      "Epoch 4/100, Loss: 0.6942934393882751\n",
      "Epoch 5/100, Loss: 0.6895110607147217\n",
      "Epoch 6/100, Loss: 0.6849775314331055\n",
      "Epoch 7/100, Loss: 0.6795083284378052\n",
      "Epoch 8/100, Loss: 0.6676356196403503\n",
      "Epoch 9/100, Loss: 0.6677995324134827\n",
      "Epoch 10/100, Loss: 0.6604330539703369\n",
      "Epoch 11/100, Loss: 0.6527548432350159\n",
      "Epoch 12/100, Loss: 0.6497433185577393\n",
      "Epoch 13/100, Loss: 0.6440480351448059\n",
      "Epoch 14/100, Loss: 0.6386942863464355\n",
      "Epoch 15/100, Loss: 0.6366676092147827\n",
      "Epoch 16/100, Loss: 0.6334262490272522\n",
      "Epoch 17/100, Loss: 0.6248083114624023\n",
      "Epoch 18/100, Loss: 0.623074471950531\n",
      "Epoch 19/100, Loss: 0.616055965423584\n",
      "Epoch 20/100, Loss: 0.6153444051742554\n",
      "Epoch 21/100, Loss: 0.6061391830444336\n",
      "Epoch 22/100, Loss: 0.607618510723114\n",
      "Epoch 23/100, Loss: 0.6024330258369446\n",
      "Epoch 24/100, Loss: 0.5987381935119629\n",
      "Epoch 25/100, Loss: 0.5954563617706299\n",
      "Epoch 26/100, Loss: 0.5883394479751587\n",
      "Epoch 27/100, Loss: 0.5838540196418762\n",
      "Epoch 28/100, Loss: 0.5829551219940186\n",
      "Epoch 29/100, Loss: 0.5761393904685974\n",
      "Epoch 30/100, Loss: 0.5733701586723328\n",
      "Epoch 31/100, Loss: 0.5712846517562866\n",
      "Epoch 32/100, Loss: 0.5685551166534424\n",
      "Epoch 33/100, Loss: 0.5652599334716797\n",
      "Epoch 34/100, Loss: 0.5636189579963684\n",
      "Epoch 35/100, Loss: 0.5561704635620117\n",
      "Epoch 36/100, Loss: 0.5527939200401306\n",
      "Epoch 37/100, Loss: 0.5529852509498596\n",
      "Epoch 38/100, Loss: 0.5510693192481995\n",
      "Epoch 39/100, Loss: 0.5463083386421204\n",
      "Epoch 40/100, Loss: 0.5433359742164612\n",
      "Epoch 41/100, Loss: 0.5442768335342407\n",
      "Epoch 42/100, Loss: 0.537512481212616\n",
      "Epoch 43/100, Loss: 0.5345052480697632\n",
      "Epoch 44/100, Loss: 0.5317427515983582\n",
      "Epoch 45/100, Loss: 0.5298560261726379\n",
      "Epoch 46/100, Loss: 0.527722954750061\n",
      "Epoch 47/100, Loss: 0.5252768993377686\n",
      "Epoch 48/100, Loss: 0.5249656438827515\n",
      "Epoch 49/100, Loss: 0.5213171243667603\n",
      "Epoch 50/100, Loss: 0.5204424262046814\n",
      "Epoch 51/100, Loss: 0.5206698775291443\n",
      "Epoch 52/100, Loss: 0.5160955786705017\n",
      "Epoch 53/100, Loss: 0.5107272863388062\n",
      "Epoch 54/100, Loss: 0.5103462934494019\n",
      "Epoch 55/100, Loss: 0.5089964866638184\n",
      "Epoch 56/100, Loss: 0.5038347244262695\n",
      "Epoch 57/100, Loss: 0.5046887397766113\n",
      "Epoch 58/100, Loss: 0.502369225025177\n",
      "Epoch 59/100, Loss: 0.49881723523139954\n",
      "Epoch 60/100, Loss: 0.49949946999549866\n",
      "Epoch 61/100, Loss: 0.49290549755096436\n",
      "Epoch 62/100, Loss: 0.49463990330696106\n",
      "Epoch 63/100, Loss: 0.4955998659133911\n",
      "Epoch 64/100, Loss: 0.48819640278816223\n",
      "Epoch 65/100, Loss: 0.48821839690208435\n",
      "Epoch 66/100, Loss: 0.48708733916282654\n",
      "Epoch 67/100, Loss: 0.4839725196361542\n",
      "Epoch 68/100, Loss: 0.48541316390037537\n",
      "Epoch 69/100, Loss: 0.4804852306842804\n",
      "Epoch 70/100, Loss: 0.47865384817123413\n",
      "Epoch 71/100, Loss: 0.47784462571144104\n",
      "Epoch 72/100, Loss: 0.47654786705970764\n",
      "Epoch 73/100, Loss: 0.4718996584415436\n",
      "Epoch 74/100, Loss: 0.46981680393218994\n",
      "Epoch 75/100, Loss: 0.47071292996406555\n",
      "Epoch 76/100, Loss: 0.4669055938720703\n",
      "Epoch 77/100, Loss: 0.4629415273666382\n",
      "Epoch 78/100, Loss: 0.4619561731815338\n",
      "Epoch 79/100, Loss: 0.4601994454860687\n",
      "Epoch 80/100, Loss: 0.45898643136024475\n",
      "Epoch 81/100, Loss: 0.45874160528182983\n",
      "Epoch 82/100, Loss: 0.4551040828227997\n",
      "Epoch 83/100, Loss: 0.4499151110649109\n",
      "Epoch 84/100, Loss: 0.4513620436191559\n",
      "Epoch 85/100, Loss: 0.44870004057884216\n",
      "Epoch 86/100, Loss: 0.4489319622516632\n",
      "Epoch 87/100, Loss: 0.44499245285987854\n",
      "Epoch 88/100, Loss: 0.4447701871395111\n",
      "Epoch 89/100, Loss: 0.4437505602836609\n",
      "Epoch 90/100, Loss: 0.4349311292171478\n",
      "Epoch 91/100, Loss: 0.44098398089408875\n",
      "Epoch 92/100, Loss: 0.43549245595932007\n",
      "Epoch 93/100, Loss: 0.4358445107936859\n",
      "Epoch 94/100, Loss: 0.4346635043621063\n",
      "Epoch 95/100, Loss: 0.426425576210022\n",
      "Epoch 96/100, Loss: 0.42837831377983093\n",
      "Epoch 97/100, Loss: 0.4246193468570709\n",
      "Epoch 98/100, Loss: 0.4220203161239624\n",
      "Epoch 99/100, Loss: 0.4231356382369995\n",
      "Epoch 100/100, Loss: 0.41987133026123047\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and train\n",
    "torch.manual_seed(0)\n",
    "num_classes = 1  \n",
    "model = StaticEmbeddingCNN(embedding_matrix, num_classes)\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fec662",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7495309568480301, F1 score: 0.7534626038781164\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525043d6",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff00a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7673466205596924\n",
      "Epoch 2/5, Loss: 0.723188042640686\n",
      "Epoch 3/5, Loss: 0.6984388828277588\n",
      "Epoch 4/5, Loss: 0.6962231397628784\n",
      "Epoch 5/5, Loss: 0.697930097579956\n",
      "Accuracy: 0.5037523452157598, F1 score: 0.6675047140163419\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7386230230331421\n",
      "Epoch 2/5, Loss: 0.6977089643478394\n",
      "Epoch 3/5, Loss: 0.695817232131958\n",
      "Epoch 4/5, Loss: 0.701389729976654\n",
      "Epoch 5/5, Loss: 0.6976956129074097\n",
      "Accuracy: 0.5178236397748592, F1 score: 0.6683870967741935\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.6975057125091553\n",
      "Epoch 2/5, Loss: 0.6967837810516357\n",
      "Epoch 3/5, Loss: 0.6847727298736572\n",
      "Epoch 4/5, Loss: 0.6827982664108276\n",
      "Epoch 5/5, Loss: 0.6737740635871887\n",
      "Accuracy: 0.6416510318949343, F1 score: 0.6723842195540308\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7020481824874878\n",
      "Epoch 2/5, Loss: 0.9752099514007568\n",
      "Epoch 3/5, Loss: 0.6570923328399658\n",
      "Epoch 4/5, Loss: 0.8268482685089111\n",
      "Epoch 5/5, Loss: 0.7156766057014465\n",
      "Accuracy: 0.6613508442776735, F1 score: 0.6984126984126984\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7055533528327942\n",
      "Epoch 2/5, Loss: 2.042435884475708\n",
      "Epoch 3/5, Loss: 0.8029919862747192\n",
      "Epoch 4/5, Loss: 1.059849739074707\n",
      "Epoch 5/5, Loss: 1.1510106325149536\n",
      "Accuracy: 0.5, F1 score: 0.0\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7182660698890686\n",
      "Epoch 2/5, Loss: 2.708139181137085\n",
      "Epoch 3/5, Loss: 1.0456385612487793\n",
      "Epoch 4/5, Loss: 1.0061272382736206\n",
      "Epoch 5/5, Loss: 1.2361505031585693\n",
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7018378973007202\n",
      "Epoch 2/5, Loss: 22.64702796936035\n",
      "Epoch 3/5, Loss: 3.718083620071411\n",
      "Epoch 4/5, Loss: 0.7067887783050537\n",
      "Epoch 5/5, Loss: 0.723317563533783\n",
      "Accuracy: 0.50093808630394, F1 score: 0.014814814814814815\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7376405596733093\n",
      "Epoch 2/5, Loss: 41.96371078491211\n",
      "Epoch 3/5, Loss: 6.439911365509033\n",
      "Epoch 4/5, Loss: 0.7577118873596191\n",
      "Epoch 5/5, Loss: 0.7666823863983154\n",
      "Accuracy: 0.5056285178236398, F1 score: 0.6566775244299674\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7105705738067627\n",
      "Epoch 2/5, Loss: 59.208984375\n",
      "Epoch 3/5, Loss: 8.042436599731445\n",
      "Epoch 4/5, Loss: 0.7712531685829163\n",
      "Epoch 5/5, Loss: 0.8891463279724121\n",
      "Accuracy: 0.5, F1 score: 0.18376722817764166\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.6981932520866394\n",
      "Epoch 2/5, Loss: 0.692474365234375\n",
      "Epoch 3/5, Loss: 0.688672661781311\n",
      "Epoch 4/5, Loss: 0.6801473498344421\n",
      "Epoch 5/5, Loss: 0.6769774556159973\n",
      "Accuracy: 0.5881801125703565, F1 score: 0.6671721000758151\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.6964465975761414\n",
      "Epoch 2/5, Loss: 0.6926811337471008\n",
      "Epoch 3/5, Loss: 0.6810831427574158\n",
      "Epoch 4/5, Loss: 0.6756145358085632\n",
      "Epoch 5/5, Loss: 0.667629063129425\n",
      "Accuracy: 0.6594746716697936, F1 score: 0.6867989646246765\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.6979082822799683\n",
      "Epoch 2/5, Loss: 0.6858465671539307\n",
      "Epoch 3/5, Loss: 0.6820815205574036\n",
      "Epoch 4/5, Loss: 0.6676226258277893\n",
      "Epoch 5/5, Loss: 0.6627875566482544\n",
      "Accuracy: 0.6566604127579737, F1 score: 0.6064516129032258\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7131870985031128\n",
      "Epoch 2/5, Loss: 1.5237505435943604\n",
      "Epoch 3/5, Loss: 0.7607307434082031\n",
      "Epoch 4/5, Loss: 0.8326990604400635\n",
      "Epoch 5/5, Loss: 0.9201859831809998\n",
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.701475203037262\n",
      "Epoch 2/5, Loss: 1.4758723974227905\n",
      "Epoch 3/5, Loss: 0.7210152745246887\n",
      "Epoch 4/5, Loss: 0.9519292712211609\n",
      "Epoch 5/5, Loss: 0.7083479166030884\n",
      "Accuracy: 0.6613508442776735, F1 score: 0.7057864710676447\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.6960848569869995\n",
      "Epoch 2/5, Loss: 2.239736795425415\n",
      "Epoch 3/5, Loss: 0.6393424272537231\n",
      "Epoch 4/5, Loss: 1.2960271835327148\n",
      "Epoch 5/5, Loss: 0.8888989090919495\n",
      "Accuracy: 0.6697936210131332, F1 score: 0.7001703577512777\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7010711431503296\n",
      "Epoch 2/5, Loss: 16.851919174194336\n",
      "Epoch 3/5, Loss: 2.7045187950134277\n",
      "Epoch 4/5, Loss: 1.46321702003479\n",
      "Epoch 5/5, Loss: 0.7152900695800781\n",
      "Accuracy: 0.49624765478424016, F1 score: 0.6408026755852843\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7144376635551453\n",
      "Epoch 2/5, Loss: 53.10309982299805\n",
      "Epoch 3/5, Loss: 7.594097137451172\n",
      "Epoch 4/5, Loss: 0.7344228029251099\n",
      "Epoch 5/5, Loss: 0.7505612373352051\n",
      "Accuracy: 0.49530956848030017, F1 score: 0.014652014652014652\n",
      "Training with hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7041358351707458\n",
      "Epoch 2/5, Loss: 64.32759094238281\n",
      "Epoch 3/5, Loss: 3.1734778881073\n",
      "Epoch 4/5, Loss: 11.199766159057617\n",
      "Epoch 5/5, Loss: 8.745903968811035\n",
      "Accuracy: 0.5, F1 score: 0.0\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.717438817024231\n",
      "Epoch 2/5, Loss: 0.7053788900375366\n",
      "Epoch 3/5, Loss: 0.7057508826255798\n",
      "Epoch 4/5, Loss: 0.7058331370353699\n",
      "Epoch 5/5, Loss: 0.693501889705658\n",
      "Accuracy: 0.6191369606003753, F1 score: 0.5708245243128964\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7216657400131226\n",
      "Epoch 2/5, Loss: 0.7068672180175781\n",
      "Epoch 3/5, Loss: 0.7076213955879211\n",
      "Epoch 4/5, Loss: 0.6950287818908691\n",
      "Epoch 5/5, Loss: 0.6864227056503296\n",
      "Accuracy: 0.624765478424015, F1 score: 0.4910941475826972\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7121010422706604\n",
      "Epoch 2/5, Loss: 0.7036466002464294\n",
      "Epoch 3/5, Loss: 0.6929128170013428\n",
      "Epoch 4/5, Loss: 0.6889337301254272\n",
      "Epoch 5/5, Loss: 0.6831929683685303\n",
      "Accuracy: 0.6463414634146342, F1 score: 0.5950590762620838\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7350414395332336\n",
      "Epoch 2/5, Loss: 1.3393357992172241\n",
      "Epoch 3/5, Loss: 0.7958933711051941\n",
      "Epoch 4/5, Loss: 0.7417342662811279\n",
      "Epoch 5/5, Loss: 0.8861952424049377\n",
      "Accuracy: 0.5, F1 score: 0.0\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7151409387588501\n",
      "Epoch 2/5, Loss: 0.6674131155014038\n",
      "Epoch 3/5, Loss: 1.1569164991378784\n",
      "Epoch 4/5, Loss: 0.6423435211181641\n",
      "Epoch 5/5, Loss: 0.8428841829299927\n",
      "Accuracy: 0.5046904315196998, F1 score: 0.01858736059479554\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7392057776451111\n",
      "Epoch 2/5, Loss: 2.8171980381011963\n",
      "Epoch 3/5, Loss: 1.1691228151321411\n",
      "Epoch 4/5, Loss: 0.8840858936309814\n",
      "Epoch 5/5, Loss: 1.2359871864318848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.8026230335235596\n",
      "Epoch 2/5, Loss: 20.590822219848633\n",
      "Epoch 3/5, Loss: 3.93654465675354\n",
      "Epoch 4/5, Loss: 0.743939995765686\n",
      "Epoch 5/5, Loss: 0.7349662184715271\n",
      "Accuracy: 0.49530956848030017, F1 score: 0.039285714285714285\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7389894723892212\n",
      "Epoch 2/5, Loss: 41.76652908325195\n",
      "Epoch 3/5, Loss: 6.372738361358643\n",
      "Epoch 4/5, Loss: 0.7537696957588196\n",
      "Epoch 5/5, Loss: 0.7640511393547058\n",
      "Accuracy: 0.50093808630394, F1 score: 0.06007067137809187\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7309091687202454\n",
      "Epoch 2/5, Loss: 61.086822509765625\n",
      "Epoch 3/5, Loss: 8.831815719604492\n",
      "Epoch 4/5, Loss: 0.7799745798110962\n",
      "Epoch 5/5, Loss: 0.8331995010375977\n",
      "Accuracy: 0.4981238273921201, F1 score: 0.1272430668841762\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7575164437294006\n",
      "Epoch 2/5, Loss: 0.7191597819328308\n",
      "Epoch 3/5, Loss: 0.7096120119094849\n",
      "Epoch 4/5, Loss: 0.7134929895401001\n",
      "Epoch 5/5, Loss: 0.7154785990715027\n",
      "Accuracy: 0.5075046904315197, F1 score: 0.03669724770642202\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7116268277168274\n",
      "Epoch 2/5, Loss: 0.7106653451919556\n",
      "Epoch 3/5, Loss: 0.6953356862068176\n",
      "Epoch 4/5, Loss: 0.6926584839820862\n",
      "Epoch 5/5, Loss: 0.6839141249656677\n",
      "Accuracy: 0.6135084427767354, F1 score: 0.46770025839793283\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7161136865615845\n",
      "Epoch 2/5, Loss: 0.7253816723823547\n",
      "Epoch 3/5, Loss: 0.70234614610672\n",
      "Epoch 4/5, Loss: 0.6947563886642456\n",
      "Epoch 5/5, Loss: 0.6929342746734619\n",
      "Accuracy: 0.5469043151969981, F1 score: 0.671651937457512\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7207680344581604\n",
      "Epoch 2/5, Loss: 1.516036868095398\n",
      "Epoch 3/5, Loss: 0.821624755859375\n",
      "Epoch 4/5, Loss: 0.7423629760742188\n",
      "Epoch 5/5, Loss: 0.8968837857246399\n",
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7109928131103516\n",
      "Epoch 2/5, Loss: 1.9812135696411133\n",
      "Epoch 3/5, Loss: 0.642296314239502\n",
      "Epoch 4/5, Loss: 1.394887089729309\n",
      "Epoch 5/5, Loss: 1.0818393230438232\n",
      "Accuracy: 0.5459662288930581, F1 score: 0.17687074829931973\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7301267981529236\n",
      "Epoch 2/5, Loss: 3.2754833698272705\n",
      "Epoch 3/5, Loss: 1.3401274681091309\n",
      "Epoch 4/5, Loss: 0.8567866086959839\n",
      "Epoch 5/5, Loss: 1.2057346105575562\n",
      "Accuracy: 0.5, F1 score: 0.0\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7169015407562256\n",
      "Epoch 2/5, Loss: 26.13953971862793\n",
      "Epoch 3/5, Loss: 3.733543872833252\n",
      "Epoch 4/5, Loss: 0.708170473575592\n",
      "Epoch 5/5, Loss: 0.7123875021934509\n",
      "Accuracy: 0.5046904315196998, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7131396532058716\n",
      "Epoch 2/5, Loss: 25.55502700805664\n",
      "Epoch 3/5, Loss: 18.446481704711914\n",
      "Epoch 4/5, Loss: 9.511327743530273\n",
      "Epoch 5/5, Loss: 1.8995486497879028\n",
      "Accuracy: 0.49624765478424016, F1 score: 0.6603415559772297\n",
      "Training with hyperparameters: {'dropout_prob': 0.5, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7108457088470459\n",
      "Epoch 2/5, Loss: 11.135650634765625\n",
      "Epoch 3/5, Loss: 69.49665832519531\n",
      "Epoch 4/5, Loss: 32.82217788696289\n",
      "Epoch 5/5, Loss: 7.248332977294922\n",
      "Accuracy: 0.549718574108818, F1 score: 0.25\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7945916652679443\n",
      "Epoch 2/5, Loss: 0.7571165561676025\n",
      "Epoch 3/5, Loss: 0.7327690720558167\n",
      "Epoch 4/5, Loss: 0.7169905304908752\n",
      "Epoch 5/5, Loss: 0.7231842279434204\n",
      "Accuracy: 0.5056285178236398, F1 score: 0.6658211794546608\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7279261946678162\n",
      "Epoch 2/5, Loss: 0.7224191427230835\n",
      "Epoch 3/5, Loss: 0.7161886096000671\n",
      "Epoch 4/5, Loss: 0.7061062455177307\n",
      "Epoch 5/5, Loss: 0.7013093829154968\n",
      "Accuracy: 0.5956848030018762, F1 score: 0.6828550404709345\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7323237657546997\n",
      "Epoch 2/5, Loss: 0.7347366809844971\n",
      "Epoch 3/5, Loss: 0.7186946272850037\n",
      "Epoch 4/5, Loss: 0.7077352404594421\n",
      "Epoch 5/5, Loss: 0.7009747624397278\n",
      "Accuracy: 0.5534709193245778, F1 score: 0.6770691994572592\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7368596792221069\n",
      "Epoch 2/5, Loss: 0.728010356426239\n",
      "Epoch 3/5, Loss: 0.7368533611297607\n",
      "Epoch 4/5, Loss: 0.674700915813446\n",
      "Epoch 5/5, Loss: 0.6491967439651489\n",
      "Accuracy: 0.5853658536585366, F1 score: 0.31790123456790126\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7280898690223694\n",
      "Epoch 2/5, Loss: 1.6145365238189697\n",
      "Epoch 3/5, Loss: 0.6730905175209045\n",
      "Epoch 4/5, Loss: 1.1496384143829346\n",
      "Epoch 5/5, Loss: 1.0126110315322876\n",
      "Accuracy: 0.5037523452157598, F1 score: 0.6675047140163419\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7304142713546753\n",
      "Epoch 2/5, Loss: 1.8834248781204224\n",
      "Epoch 3/5, Loss: 0.6600174903869629\n",
      "Epoch 4/5, Loss: 1.320320725440979\n",
      "Epoch 5/5, Loss: 1.035249948501587\n",
      "Accuracy: 0.5328330206378987, F1 score: 0.12937062937062938\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7273721694946289\n",
      "Epoch 2/5, Loss: 21.44748878479004\n",
      "Epoch 3/5, Loss: 3.175858736038208\n",
      "Epoch 4/5, Loss: 0.7191179990768433\n",
      "Epoch 5/5, Loss: 0.7200967669487\n",
      "Accuracy: 0.5093808630393997, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7364270687103271\n",
      "Epoch 2/5, Loss: 26.698915481567383\n",
      "Epoch 3/5, Loss: 11.5126314163208\n",
      "Epoch 4/5, Loss: 7.227492332458496\n",
      "Epoch 5/5, Loss: 1.638806939125061\n",
      "Accuracy: 0.4971857410881801, F1 score: 0.03597122302158273\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [2, 3, 4], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7340675592422485\n",
      "Epoch 2/5, Loss: 59.03409194946289\n",
      "Epoch 3/5, Loss: 5.813004970550537\n",
      "Epoch 4/5, Loss: 2.8223989009857178\n",
      "Epoch 5/5, Loss: 2.441946506500244\n",
      "Accuracy: 0.50187617260788, F1 score: 0.667501565435191\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7194210290908813\n",
      "Epoch 2/5, Loss: 0.711067795753479\n",
      "Epoch 3/5, Loss: 0.7076040506362915\n",
      "Epoch 4/5, Loss: 0.7026007771492004\n",
      "Epoch 5/5, Loss: 0.6923457980155945\n",
      "Accuracy: 0.6172607879924953, F1 score: 0.6559865092748736\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.737212061882019\n",
      "Epoch 2/5, Loss: 0.7261255383491516\n",
      "Epoch 3/5, Loss: 0.7199397087097168\n",
      "Epoch 4/5, Loss: 0.7096275687217712\n",
      "Epoch 5/5, Loss: 0.7044087052345276\n",
      "Accuracy: 0.5712945590994372, F1 score: 0.6841741534208707\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.001, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.8188225626945496\n",
      "Epoch 2/5, Loss: 0.7324311137199402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.7483795881271362\n",
      "Epoch 4/5, Loss: 0.7572798728942871\n",
      "Epoch 5/5, Loss: 0.7350382804870605\n",
      "Accuracy: 0.5300187617260788, F1 score: 0.14065180102915953\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7480978965759277\n",
      "Epoch 2/5, Loss: 1.3628031015396118\n",
      "Epoch 3/5, Loss: 0.8107272982597351\n",
      "Epoch 4/5, Loss: 0.7079648971557617\n",
      "Epoch 5/5, Loss: 0.815915584564209\n",
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7418350577354431\n",
      "Epoch 2/5, Loss: 2.134641408920288\n",
      "Epoch 3/5, Loss: 0.8060808181762695\n",
      "Epoch 4/5, Loss: 1.1376022100448608\n",
      "Epoch 5/5, Loss: 1.126815676689148\n",
      "Accuracy: 0.50093808630394, F1 score: 0.003745318352059925\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.7424008846282959\n",
      "Epoch 2/5, Loss: 2.957378387451172\n",
      "Epoch 3/5, Loss: 0.8990917205810547\n",
      "Epoch 4/5, Loss: 1.4544347524642944\n",
      "Epoch 5/5, Loss: 1.4267382621765137\n",
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 50}\n",
      "Epoch 1/5, Loss: 0.7371972799301147\n",
      "Epoch 2/5, Loss: 15.870243072509766\n",
      "Epoch 3/5, Loss: 7.02562141418457\n",
      "Epoch 4/5, Loss: 3.6496033668518066\n",
      "Epoch 5/5, Loss: 0.9274261593818665\n",
      "Accuracy: 0.4971857410881801, F1 score: 0.0726643598615917\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 100}\n",
      "Epoch 1/5, Loss: 0.7394130825996399\n",
      "Epoch 2/5, Loss: 51.330501556396484\n",
      "Epoch 3/5, Loss: 6.995816230773926\n",
      "Epoch 4/5, Loss: 1.5888006687164307\n",
      "Epoch 5/5, Loss: 1.4349206686019897\n",
      "Accuracy: 0.49437148217636023, F1 score: 0.0036968576709796672\n",
      "Training with hyperparameters: {'dropout_prob': 0.7, 'kernel_sizes': [3, 4, 5], 'lr': 0.1, 'num_filters': 150}\n",
      "Epoch 1/5, Loss: 0.8525954484939575\n",
      "Epoch 2/5, Loss: 76.11186981201172\n",
      "Epoch 3/5, Loss: 11.605973243713379\n",
      "Epoch 4/5, Loss: 0.8176372051239014\n",
      "Epoch 5/5, Loss: 0.7686228156089783\n",
      "Accuracy: 0.48874296435272047, F1 score: 0.018018018018018018\n",
      "Best F1 score: 0.7057864710676447\n",
      "Best hyperparameters: {'dropout_prob': 0.3, 'kernel_sizes': [3, 4, 5], 'lr': 0.01, 'num_filters': 100}\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_filters': [50, 100, 150],\n",
    "    'dropout_prob': [0.3, 0.5, 0.7],\n",
    "    'kernel_sizes': [[2, 3, 4], [3, 4, 5]],\n",
    "    'lr': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "param_grid = list(ParameterGrid(hyperparameters))\n",
    "\n",
    "best_f1_score = 0\n",
    "best_params = None\n",
    "\n",
    "for params in param_grid:\n",
    "    print(\"Training with hyperparameters:\", params)\n",
    "    cnn_params = {key: value for key, value in params.items() if key != 'lr'}\n",
    "    # to tune: kernel_sizes, num_filters, dropout_prob\n",
    "    model = StaticEmbeddingCNN(embedding_matrix, num_classes, **cnn_params)\n",
    "    train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs=5, lr=params['lr'])\n",
    "    _, f1 = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best F1 score:\", best_f1_score)\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63d51c",
   "metadata": {},
   "source": [
    "# Other Tested NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4dcf5",
   "metadata": {},
   "source": [
    "## MoreComplexCNN (from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5084853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreComplexCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, kernel_num, num_classes, kernel_sizes=[3, 4, 5], dropout_prob=0.5):\n",
    "        super(MoreComplexCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.conv_block = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(in_channels=embedding_matrix.shape[1], out_channels=kernel_num, kernel_size=k, stride=1) \n",
    "                for k in kernel_sizes\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(len(kernel_sizes) * kernel_num, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "\n",
    "        conv_outputs = [F.relu(conv(embedded)) for conv in self.conv_block] \n",
    "\n",
    "        pooled_outputs = [F.max_pool1d(conv_output, conv_output.size(2)).squeeze(2) for conv_output in conv_outputs]  # Pooling\n",
    "\n",
    "        concat = torch.cat(pooled_outputs, dim=1)\n",
    "\n",
    "        output = self.dropout(concat)\n",
    "        output = self.linear(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb67befa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7030304670333862\n",
      "Epoch 2/100, Loss: 0.6919169425964355\n",
      "Epoch 3/100, Loss: 0.6889169216156006\n",
      "Epoch 4/100, Loss: 0.6857153177261353\n",
      "Epoch 5/100, Loss: 0.6766760945320129\n",
      "Epoch 6/100, Loss: 0.6786852478981018\n",
      "Epoch 7/100, Loss: 0.6756353974342346\n",
      "Epoch 8/100, Loss: 0.6680417060852051\n",
      "Epoch 9/100, Loss: 0.6662741303443909\n",
      "Epoch 10/100, Loss: 0.6678453087806702\n",
      "Epoch 11/100, Loss: 0.6645626425743103\n",
      "Epoch 12/100, Loss: 0.6608788967132568\n",
      "Epoch 13/100, Loss: 0.6608502864837646\n",
      "Epoch 14/100, Loss: 0.658575713634491\n",
      "Epoch 15/100, Loss: 0.6522707343101501\n",
      "Epoch 16/100, Loss: 0.6535550951957703\n",
      "Epoch 17/100, Loss: 0.6519927382469177\n",
      "Epoch 18/100, Loss: 0.6485595703125\n",
      "Epoch 19/100, Loss: 0.6507163643836975\n",
      "Epoch 20/100, Loss: 0.6473495960235596\n",
      "Epoch 21/100, Loss: 0.6444655060768127\n",
      "Epoch 22/100, Loss: 0.6443787813186646\n",
      "Epoch 23/100, Loss: 0.6461484432220459\n",
      "Epoch 24/100, Loss: 0.6411661505699158\n",
      "Epoch 25/100, Loss: 0.641717255115509\n",
      "Epoch 26/100, Loss: 0.6416459083557129\n",
      "Epoch 27/100, Loss: 0.6367805004119873\n",
      "Epoch 28/100, Loss: 0.6368531584739685\n",
      "Epoch 29/100, Loss: 0.6340067386627197\n",
      "Epoch 30/100, Loss: 0.6332475543022156\n",
      "Epoch 31/100, Loss: 0.6319448351860046\n",
      "Epoch 32/100, Loss: 0.6299914717674255\n",
      "Epoch 33/100, Loss: 0.6300770044326782\n",
      "Epoch 34/100, Loss: 0.6299671530723572\n",
      "Epoch 35/100, Loss: 0.6259563565254211\n",
      "Epoch 36/100, Loss: 0.6263629794120789\n",
      "Epoch 37/100, Loss: 0.6277562975883484\n",
      "Epoch 38/100, Loss: 0.6238377094268799\n",
      "Epoch 39/100, Loss: 0.6232856512069702\n",
      "Epoch 40/100, Loss: 0.6210998296737671\n",
      "Epoch 41/100, Loss: 0.6190868616104126\n",
      "Epoch 42/100, Loss: 0.6201804876327515\n",
      "Epoch 43/100, Loss: 0.6158238053321838\n",
      "Epoch 44/100, Loss: 0.6150838136672974\n",
      "Epoch 45/100, Loss: 0.6114503145217896\n",
      "Epoch 46/100, Loss: 0.6111378073692322\n",
      "Epoch 47/100, Loss: 0.6110885739326477\n",
      "Epoch 48/100, Loss: 0.6084195971488953\n",
      "Epoch 49/100, Loss: 0.606564462184906\n",
      "Epoch 50/100, Loss: 0.6065085530281067\n",
      "Epoch 51/100, Loss: 0.603644609451294\n",
      "Epoch 52/100, Loss: 0.6011015176773071\n",
      "Epoch 53/100, Loss: 0.6009132862091064\n",
      "Epoch 54/100, Loss: 0.6000649333000183\n",
      "Epoch 55/100, Loss: 0.6003074645996094\n",
      "Epoch 56/100, Loss: 0.5971465110778809\n",
      "Epoch 57/100, Loss: 0.5965928435325623\n",
      "Epoch 58/100, Loss: 0.5899758338928223\n",
      "Epoch 59/100, Loss: 0.5915369987487793\n",
      "Epoch 60/100, Loss: 0.5899612307548523\n",
      "Epoch 61/100, Loss: 0.5874713659286499\n",
      "Epoch 62/100, Loss: 0.5860669612884521\n",
      "Epoch 63/100, Loss: 0.5866850018501282\n",
      "Epoch 64/100, Loss: 0.5830056667327881\n",
      "Epoch 65/100, Loss: 0.5836251974105835\n",
      "Epoch 66/100, Loss: 0.5770226716995239\n",
      "Epoch 67/100, Loss: 0.57659912109375\n",
      "Epoch 68/100, Loss: 0.5779355764389038\n",
      "Epoch 69/100, Loss: 0.5728530287742615\n",
      "Epoch 70/100, Loss: 0.5715147852897644\n",
      "Epoch 71/100, Loss: 0.5727890729904175\n",
      "Epoch 72/100, Loss: 0.572800874710083\n",
      "Epoch 73/100, Loss: 0.5698031783103943\n",
      "Epoch 74/100, Loss: 0.5631877183914185\n",
      "Epoch 75/100, Loss: 0.5626721382141113\n",
      "Epoch 76/100, Loss: 0.5608676075935364\n",
      "Epoch 77/100, Loss: 0.5613693594932556\n",
      "Epoch 78/100, Loss: 0.5531036853790283\n",
      "Epoch 79/100, Loss: 0.5572292804718018\n",
      "Epoch 80/100, Loss: 0.554793655872345\n",
      "Epoch 81/100, Loss: 0.5507888197898865\n",
      "Epoch 82/100, Loss: 0.552745521068573\n",
      "Epoch 83/100, Loss: 0.5486544966697693\n",
      "Epoch 84/100, Loss: 0.5468870997428894\n",
      "Epoch 85/100, Loss: 0.5463336110115051\n",
      "Epoch 86/100, Loss: 0.5413163304328918\n",
      "Epoch 87/100, Loss: 0.5440353155136108\n",
      "Epoch 88/100, Loss: 0.5374178290367126\n",
      "Epoch 89/100, Loss: 0.5397244095802307\n",
      "Epoch 90/100, Loss: 0.5354995727539062\n",
      "Epoch 91/100, Loss: 0.5315453410148621\n",
      "Epoch 92/100, Loss: 0.5327363014221191\n",
      "Epoch 93/100, Loss: 0.5339871048927307\n",
      "Epoch 94/100, Loss: 0.5304846167564392\n",
      "Epoch 95/100, Loss: 0.5226169228553772\n",
      "Epoch 96/100, Loss: 0.5270147919654846\n",
      "Epoch 97/100, Loss: 0.5259081721305847\n",
      "Epoch 98/100, Loss: 0.5267359614372253\n",
      "Epoch 99/100, Loss: 0.5244223475456238\n",
      "Epoch 100/100, Loss: 0.5199669003486633\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and train\n",
    "torch.manual_seed(0)\n",
    "num_classes = 1  \n",
    "model = MoreComplexCNN(embedding_matrix=embedding_matrix, num_classes=num_classes, kernel_num=1)\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7a0a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7073170731707317, F1 score: 0.7051039697542533\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8eeba",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29952a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticEmbeddingLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, hidden_size=100, num_layers=1, dropout_prob=0.5):\n",
    "        super(StaticEmbeddingLSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_matrix.shape[1], hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # Multiply by 2 for bidirectional LSTM\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "\n",
    "        # Take the last output of the forward and backward LSTM\n",
    "        last_output_forward = lstm_output[:, -1, :lstm_output.size(2)//2]\n",
    "        last_output_backward = lstm_output[:, 0, lstm_output.size(2)//2:]\n",
    "\n",
    "        concatenated_output = torch.cat((last_output_forward, last_output_backward), dim=1)\n",
    "\n",
    "        output = self.dropout(concatenated_output)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4861803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6975608468055725\n",
      "Epoch 2/10, Loss: 0.6935566067695618\n",
      "Epoch 3/10, Loss: 0.6915398240089417\n",
      "Epoch 4/10, Loss: 0.6925466060638428\n",
      "Epoch 5/10, Loss: 0.6916471123695374\n",
      "Epoch 6/10, Loss: 0.6903289556503296\n",
      "Epoch 7/10, Loss: 0.6892625093460083\n",
      "Epoch 8/10, Loss: 0.6874939799308777\n",
      "Epoch 9/10, Loss: 0.6868316531181335\n",
      "Epoch 10/10, Loss: 0.6867664456367493\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and train\n",
    "torch.manual_seed(0)\n",
    "num_classes = 1  \n",
    "model = StaticEmbeddingLSTM(embedding_matrix, num_classes)\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da33e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5581613508442776, F1 score: 0.642369020501139\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71a42f",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e63614d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StaticEmbeddingRNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, hidden_size=100, num_layers=1, dropout_prob=0.5):\n",
    "        super(StaticEmbeddingRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        self.rnn = nn.RNN(input_size=embedding_matrix.shape[1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) \n",
    "        \n",
    "        rnn_output, _ = self.rnn(embedded)\n",
    "        \n",
    "        last_output = rnn_output[:, -1, :]\n",
    "        \n",
    "        output = self.dropout(last_output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85000468",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = StaticEmbeddingRNN(embedding_matrix=embedding_matrix,\n",
    "                           num_classes=num_classes,\n",
    "                           hidden_size=128,  \n",
    "                           num_layers=1,     \n",
    "                           dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca1c3819",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7040256857872009\n",
      "Epoch 2/10, Loss: 0.6959689855575562\n",
      "Epoch 3/10, Loss: 0.6990081667900085\n",
      "Epoch 4/10, Loss: 0.6974896192550659\n",
      "Epoch 5/10, Loss: 0.6958703398704529\n",
      "Epoch 6/10, Loss: 0.6945583820343018\n",
      "Epoch 7/10, Loss: 0.6959335803985596\n",
      "Epoch 8/10, Loss: 0.6951942443847656\n",
      "Epoch 9/10, Loss: 0.6954545974731445\n",
      "Epoch 10/10, Loss: 0.6959737539291382\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and train\n",
    "torch.manual_seed(0)\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4730e6ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad604d4",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d034ba43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StaticEmbeddingGRU(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, hidden_size=30, num_layers=2, dropout_prob=0.5):\n",
    "        super(StaticEmbeddingGRU, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        self.gru = nn.GRU(input_size=embedding_matrix.shape[1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  \n",
    "    \n",
    "        gru_output, _ = self.gru(embedded)\n",
    "        \n",
    "        last_output = gru_output[:, -1, :]\n",
    "        \n",
    "        output = self.dropout(last_output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bc0bbcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = StaticEmbeddingGRU(embedding_matrix=embedding_matrix,\n",
    "                           num_classes=num_classes,\n",
    "                           hidden_size=128,  \n",
    "                           num_layers=1,     \n",
    "                           dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23e8860f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.699726402759552\n",
      "Epoch 2/20, Loss: 0.6957173943519592\n",
      "Epoch 3/20, Loss: 0.6962710022926331\n",
      "Epoch 4/20, Loss: 0.6977770924568176\n",
      "Epoch 5/20, Loss: 0.6956571936607361\n",
      "Epoch 6/20, Loss: 0.6954718232154846\n",
      "Epoch 7/20, Loss: 0.6953843832015991\n",
      "Epoch 8/20, Loss: 0.6956498622894287\n",
      "Epoch 9/20, Loss: 0.696336030960083\n",
      "Epoch 10/20, Loss: 0.6949511766433716\n",
      "Epoch 11/20, Loss: 0.6947197318077087\n",
      "Epoch 12/20, Loss: 0.6957190632820129\n",
      "Epoch 13/20, Loss: 0.6948350667953491\n",
      "Epoch 14/20, Loss: 0.6961090564727783\n",
      "Epoch 15/20, Loss: 0.6948580145835876\n",
      "Epoch 16/20, Loss: 0.6947367191314697\n",
      "Epoch 17/20, Loss: 0.694600522518158\n",
      "Epoch 18/20, Loss: 0.6949266195297241\n",
      "Epoch 19/20, Loss: 0.6932806372642517\n",
      "Epoch 20/20, Loss: 0.6943645477294922\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and train\n",
    "torch.manual_seed(0)\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "422755fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5, F1 score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bac78",
   "metadata": {},
   "source": [
    "# Saving  Our Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b70540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticEmbeddingCNN(\n",
       "  (embedding): Embedding(400000, 50)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(50, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(50, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(50, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11b74bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'saved_models/CNN.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d715a",
   "metadata": {},
   "source": [
    "# Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f143b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load('saved_models/CNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "989ac861",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticEmbeddingCNN(\n",
       "  (embedding): Embedding(400000, 50)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(50, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(50, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(50, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac13b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7495309568480301, F1 score: 0.7534626038781164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7495309568480301, 0.7534626038781164)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(loaded_model, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488fdb76",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3bdf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preds(model, X_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        predictions = torch.round(torch.sigmoid(outputs))\n",
    "        predictions = predictions.squeeze()\n",
    "        \n",
    "        pred_df = pd.DataFrame({'pred': predictions})\n",
    "        index_df = pd.DataFrame(list(range(0, len(predictions))), columns=['index'])\n",
    "        pred_df = pd.concat([index_df, pred_df], axis = 1)\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76ee90be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1061</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1062</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1063</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  pred\n",
       "0         0   0.0\n",
       "1         1   1.0\n",
       "2         2   0.0\n",
       "3         3   1.0\n",
       "4         4   1.0\n",
       "...     ...   ...\n",
       "1061   1061   1.0\n",
       "1062   1062   0.0\n",
       "1063   1063   0.0\n",
       "1064   1064   0.0\n",
       "1065   1065   0.0\n",
       "\n",
       "[1066 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_preds(model, X_test_tensor)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca22aa",
   "metadata": {},
   "source": [
    "# Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7cfd7f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.2.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchdata, torchtext, torchvision\n",
      "---\n",
      "Name: torchtext\n",
      "Version: 0.17.1\n",
      "Summary: Text utilities, models, transforms, and datasets for PyTorch.\n",
      "Home-page: https://github.com/pytorch/text\n",
      "Author: PyTorch Text Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD\n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: numpy, requests, torch, torchdata, tqdm\n",
      "Required-by: \n",
      "---\n",
      "Name: nltk\n",
      "Version: 3.8.1\n",
      "Summary: Natural Language Toolkit\n",
      "Home-page: https://www.nltk.org/\n",
      "Author: NLTK Team\n",
      "Author-email: nltk.team@gmail.com\n",
      "License: Apache License, Version 2.0\n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: click, joblib, regex, tqdm\n",
      "Required-by: \n",
      "---\n",
      "Name: datasets\n",
      "Version: 2.16.1\n",
      "Summary: HuggingFace community-driven open-source library of datasets\n",
      "Home-page: https://github.com/huggingface/datasets\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyarrow-hotfix, pyyaml, requests, tqdm, xxhash\n",
      "Required-by: \n",
      "---\n",
      "Name: pandas\n",
      "Version: 2.0.3\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "        \n",
      "        Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "        All rights reserved.\n",
      "        \n",
      "        Copyright (c) 2011-2023, Open source contributors.\n",
      "        \n",
      "        Redistribution and use in source and binary forms, with or without\n",
      "        modification, are permitted provided that the following conditions are met:\n",
      "        \n",
      "        * Redistributions of source code must retain the above copyright notice, this\n",
      "          list of conditions and the following disclaimer.\n",
      "        \n",
      "        * Redistributions in binary form must reproduce the above copyright notice,\n",
      "          this list of conditions and the following disclaimer in the documentation\n",
      "          and/or other materials provided with the distribution.\n",
      "        \n",
      "        * Neither the name of the copyright holder nor the names of its\n",
      "          contributors may be used to endorse or promote products derived from\n",
      "          this software without specific prior written permission.\n",
      "        \n",
      "        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "        AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "        IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "        \n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: altair, bokeh, catboost, category-encoders, datasets, datashader, geopandas, holoviews, hvplot, investpy, keplergl, panel, PDPbox, phik, seaborn, shap, statsmodels, streamlit, visions, xarray, ydata-profiling\n",
      "---\n",
      "Name: scikit-learn\n",
      "Version: 1.4.1.post1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /Users/franco/opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: bayesian-optimization, category-encoders, daal4py, eli5, imbalanced-learn, kmodes, librosa, lightgbm, PDPbox, scikit-learn-intelex, scikit-optimize, shap\n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchtext nltk datasets pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec16880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
